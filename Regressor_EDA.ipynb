{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ade9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import category_encoders as ce\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, Normalizer, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "class EDA:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def describe(self, data):\n",
    "        '''\n",
    "        '''\n",
    "        return{\n",
    "            'info': data.info(),\n",
    "            'shape': data.shape,\n",
    "            'describe': data.describe(include = 'all'),\n",
    "            'duplicates': data.duplicated().sum(),\n",
    "            'null values': data.isna().sum()\n",
    "        }\n",
    "    def drop_duplicates(self, data):\n",
    "        '''\n",
    "        '''\n",
    "        data.drop_duplicates()\n",
    "        return data\n",
    "    \n",
    "    def na_values(self, data, method = 'drop', fill_with = None):\n",
    "        '''\n",
    "        '''\n",
    "        if method == 'drop':\n",
    "            data.dropna()\n",
    "        elif method == 'fill with:':\n",
    "            for column in data.columns:\n",
    "                if data[column].isnull().any():\n",
    "                    if fill_with == 'mean':\n",
    "                        data[column] = data[column].fillna(data[column].mean())\n",
    "                    elif fill_with == 'median':\n",
    "                        data[column] = data[column].fillna(data[column].median())                        \n",
    "                    elif fill_with == 'mode':\n",
    "                        filled_data[column] = filled_data[column].fillna(filled_data[column].mode().iloc[0])\n",
    "                    elif fill_with == 'ffill':\n",
    "                        filled_data[column] = filled_data[column].fillna(method='ffill')\n",
    "                    elif fill_with == 'bfill':\n",
    "                        filled_data[column] = filled_data[column].fillna(method='bfill')\n",
    "                    elif isinstance(fill_with, dict):\n",
    "                        filled_data[column] = filled_data[column].fillna(fill_with.get(column, 0))\n",
    "                    else:\n",
    "                        filled_data[column] = filled_data[column].fillna(fill_with)\n",
    "            return filled_data\n",
    "    \n",
    "    def remove_outliers(self, data, method = 'IQR', threshold = 3, upper = None, lower = None):\n",
    "        '''\n",
    "        '''\n",
    "        outliers = {}\n",
    "        numeric_cols = data.select_dtypes(include=np.number).columns\n",
    "        if method == 'IQR':\n",
    "            for col in numeric_cols:\n",
    "                Q1 = data[col].quantile(0.25)\n",
    "                Q3 = data[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower = Q1 - 1.5 * IQR\n",
    "                upper = Q3 + 1.5 * IQR\n",
    "                outliers[col] = int(((data[col] < lower) | (data[col] > upper)).sum())\n",
    "            print(f'removing outliers: {outliers}')\n",
    "            data = data[(data[col] >= lower) & (data[col] <= upper)]\n",
    "        \n",
    "        elif method == 'zscore':\n",
    "            z_scores = np.abs(zscore(data[numeric_cols]))\n",
    "            z_scores_df = pd.DataFrame(z_scores, columns=numeric_cols)\n",
    "            for col in numeric_cols:\n",
    "                outliers[col] = int((z_scores_df[col] > threshold).sum())\n",
    "            mask = (z_scores_df < threshold).all(axis=1)\n",
    "            print(f'removing outliers: {outliers}')            \n",
    "            data = data[mask]\n",
    "\n",
    "\n",
    "        elif method == 'threshold':\n",
    "            for col in numeric_cols:\n",
    "                if lower == None:\n",
    "                    data = data[(data[col] >=-upper) & (data[col] <= upper)]\n",
    "                else: data = data[(data[col] >=lower) & (data[col] <= upper)]\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def normalize_data(self, data, method='minmax'):\n",
    "        '''\n",
    "        '''\n",
    "        numeric_cols = data.select_dtypes(include=np.number).columns\n",
    "        normed_df = data.copy()\n",
    "\n",
    "        if method == 'minmax':\n",
    "            normed_df[numeric_cols] = normed_df[numeric_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "        elif method == 'zscore':\n",
    "            normed_df[numeric_cols] = normed_df[numeric_cols].apply(lambda x: (x - x.mean()) / x.std())\n",
    "        elif method == 'log':\n",
    "            normed_df[numeric_cols] = normed_df[numeric_cols].apply(lambda x: np.log1p(x))\n",
    "        elif method == 'decimal':\n",
    "            normed_df[numeric_cols] = normed_df[numeric_cols].apply(lambda x: x / (10 ** np.ceil(np.log10(x.abs().max() + 1e-10))))\n",
    "        elif method == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "            normed_df[numeric_cols] = scaler.fit_transform(normed_df[numeric_cols])\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported normalization method: {method}\")\n",
    "\n",
    "        return normed_df\n",
    "    \n",
    "    def scale_data(self, data, method = 'standard'):\n",
    "        '''\n",
    "        '''\n",
    "        numeric_cols = data.select_dtypes(include=np.number).columns\n",
    "        scaler = None\n",
    "        if method == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif method == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif method == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "        elif method == 'maxabs':\n",
    "            scaler = MaxAbsScaler()\n",
    "        elif method == 'normalize':\n",
    "            scaler = Normalizer()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported scaling method: {method}\")\n",
    "\n",
    "        scaled_array = scaler.fit_transform(data[numeric_cols])\n",
    "        scaled_df = pd.DataFrame(scaled_array, columns=numeric_cols)\n",
    "        return scaled_df\n",
    "    \n",
    "    \n",
    "    import category_encoders as ce\n",
    "\n",
    "    def encode_data(self, data, method='onehot', cardinality_threshold=10, hashing_components=10):\n",
    "        encoded_data = data.copy()\n",
    "        cat_cols = encoded_data.select_dtypes(include='object').columns\n",
    "\n",
    "    # Report high-cardinality columns\n",
    "        high_card_cols = [col for col in cat_cols if encoded_data[col].nunique() > cardinality_threshold]\n",
    "        safe_cat_cols = [col for col in cat_cols if encoded_data[col].nunique() <= cardinality_threshold]\n",
    "\n",
    "        if high_card_cols:\n",
    "            print(f\" Warning: High-cardinality columns detected and excluded from one-hot encoding: {high_card_cols}\")\n",
    "\n",
    "        if method == 'onehot':\n",
    "            return pd.get_dummies(encoded_data, columns=safe_cat_cols, drop_first=True)\n",
    "\n",
    "        elif method == 'label':\n",
    "            le = LabelEncoder()\n",
    "            for col in cat_cols:\n",
    "                encoded_data[col] = le.fit_transform(encoded_data[col])\n",
    "            return encoded_data\n",
    "\n",
    "        elif method == 'ordinal':\n",
    "            raise NotImplementedError(\"Ordinal encoding with custom ordering not yet implemented.\")\n",
    "\n",
    "        elif method == 'frequency':\n",
    "            for col in cat_cols:\n",
    "                freq = encoded_data[col].value_counts(normalize=True)\n",
    "                encoded_data[col] = encoded_data[col].map(freq)\n",
    "            return encoded_data\n",
    "\n",
    "        elif method == 'hashing':\n",
    "            encoder = ce.HashingEncoder(cols=cat_cols, n_components=hashing_components)\n",
    "            encoded_data = encoder.fit_transform(encoded_data)\n",
    "            return encoded_data\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported encoding method: {method}\")\n",
    "        \n",
    "    def visualize_univariate(self, data, graph = 'hist', x_var= None):\n",
    "        try:\n",
    "            if graph == 'hist':\n",
    "                if not x_var:\n",
    "                    raise ValueError(\"x_var must be specified for histogram\")\n",
    "                fig = px.histogram(data, x=x_var)\n",
    "\n",
    "            elif graph == 'box':\n",
    "                if not x_var:\n",
    "                    raise ValueError(\"x_var must be specified for box plot\")\n",
    "                fig = px.box(data, y=x_var)\n",
    "\n",
    "                \n",
    "            elif graph == 'violin':\n",
    "                if not x_var:\n",
    "                    raise ValueError(\"x_var must be specified for violin plot\")\n",
    "                fig = px.violin(data, y=x_var, box=True, points=\"all\")\n",
    "            elif graph == 'heatmap':\n",
    "                # For heatmap, if x_var and y_var are None, default to correlation matrix\n",
    "                corr = data.corr()\n",
    "                fig = px.imshow(corr,\n",
    "                                text_auto=True,\n",
    "                                color_continuous_scale='RdBu_r',\n",
    "                                title='Correlation Heatmap')\n",
    "\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported graph type: {graph}\")\n",
    "                    \n",
    "\n",
    "            fig.update_layout(title=f\"{graph.title()} Plot\", title_x=0.5)\n",
    "            fig.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating {graph} plot: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7c303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
